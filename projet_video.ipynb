{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Data directory\n",
    "train_directory = 'DB/train'\n",
    "test_directory = 'DB/test'\n",
    "\n",
    "# Loading train set + Applying data augmentation on train set\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range=[0.8,1.0],\n",
    "        fill_mode=\"nearest\")\n",
    "\n",
    "# Loading test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 4736 images belonging to 5 classes.\n",
      "Found 3568 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generating train batches\n",
    "train_batches = train_datagen.flow_from_directory(\n",
    "        train_directory,\n",
    "        target_size=(224,224),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "# Generating test batches\n",
    "test_batches = test_datagen.flow_from_directory(\n",
    "        test_directory,\n",
    "        target_size=(224,224),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenetv2_1.00_224 (Functi (None, 1000)              3538984   \n_________________________________________________________________\npredictions (Dense)          (None, 5)                 5005      \n=================================================================\nTotal params: 3,543,989\nTrainable params: 3,509,877\nNon-trainable params: 34,112\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model architecture \n",
    "# We used pretrained model MobileNetV2 and loaded ImageNet's weight\n",
    "mobilenet = MobileNetV2(weights = 'imagenet', include_top = True, input_shape=(224,224,3))\n",
    "mobilenet.layers.pop()\n",
    "model = Sequential()\n",
    "model.add(mobilenet)\n",
    "model.add(Dense(5, activation='softmax', name='predictions'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.5670 - acc: 0.7035WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 480s 3s/step - loss: 1.5670 - acc: 0.7035 - val_loss: 1.5734 - val_acc: 0.4617\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.5157 - acc: 0.9113WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 444s 3s/step - loss: 1.5157 - acc: 0.9113 - val_loss: 1.5551 - val_acc: 0.5180\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.4877 - acc: 0.9367WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 453s 3s/step - loss: 1.4877 - acc: 0.9367 - val_loss: 1.5254 - val_acc: 0.6520\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.4645 - acc: 0.9493WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 437s 3s/step - loss: 1.4645 - acc: 0.9493 - val_loss: 1.5240 - val_acc: 0.6081\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.4430 - acc: 0.9578WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 437s 3s/step - loss: 1.4430 - acc: 0.9578 - val_loss: 1.4717 - val_acc: 0.7950\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.4209 - acc: 0.9662WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 418s 3s/step - loss: 1.4209 - acc: 0.9662 - val_loss: 1.4505 - val_acc: 0.8322\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.4000 - acc: 0.9738WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 411s 3s/step - loss: 1.4000 - acc: 0.9738 - val_loss: 1.4527 - val_acc: 0.7680\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.3834 - acc: 0.9688WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 414s 3s/step - loss: 1.3834 - acc: 0.9688 - val_loss: 1.4144 - val_acc: 0.8468\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.3638 - acc: 0.9747WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 410s 3s/step - loss: 1.3638 - acc: 0.9747 - val_loss: 1.4157 - val_acc: 0.8018\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.3467 - acc: 0.9713WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "148/148 [==============================] - 411s 3s/step - loss: 1.3467 - acc: 0.9713 - val_loss: 1.4072 - val_acc: 0.7973\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f5dccd080>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Model training\n",
    "num_train = 4736\n",
    "num_val = 3568\n",
    "num_epoch = 10\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['acc'])\n",
    "model.fit(\n",
    "        train_batches,\n",
    "        steps_per_epoch=num_train // batch_size,\n",
    "        epochs=num_epoch,\n",
    "        validation_data=test_batches,\n",
    "        validation_steps=num_val // batch_size,\n",
    "        callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenetv2_1.00_224 (Functi (None, 1000)              3538984   \n=================================================================\nTotal params: 3,538,984\nTrainable params: 0\nNon-trainable params: 3,538,984\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model architecture \n",
    "# We used pretrained model MobileNetV2 and loaded ImageNet's weight\n",
    "modelbis = Sequential()\n",
    "modelbis.add(mobilenet)\n",
    "modelbis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in modelbis.layers : \n",
    "    layer.trainable = False \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelbis.add(Dense(5, activation='softmax', name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenetv2_1.00_224 (Functi (None, 1000)              3538984   \n_________________________________________________________________\npredictions (Dense)          (None, 5)                 5005      \n=================================================================\nTotal params: 3,543,989\nTrainable params: 5,005\nNon-trainable params: 3,538,984\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelbis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "148/148 [==============================] - 88s 592ms/step - loss: 1.6234 - acc: 0.1005 - val_loss: 1.6187 - val_acc: 0.1689\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 94s 637ms/step - loss: 1.6075 - acc: 0.2196 - val_loss: 1.6062 - val_acc: 0.3063\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 100s 673ms/step - loss: 1.5931 - acc: 0.4223 - val_loss: 1.5942 - val_acc: 0.3345\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 101s 685ms/step - loss: 1.5789 - acc: 0.5338 - val_loss: 1.5814 - val_acc: 0.4381\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 96s 652ms/step - loss: 1.5632 - acc: 0.5693 - val_loss: 1.5679 - val_acc: 0.4437\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 89s 604ms/step - loss: 1.5482 - acc: 0.7052 - val_loss: 1.5527 - val_acc: 0.6104\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 84s 569ms/step - loss: 1.5335 - acc: 0.7179 - val_loss: 1.5423 - val_acc: 0.5957\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 88s 598ms/step - loss: 1.5204 - acc: 0.7331 - val_loss: 1.5293 - val_acc: 0.5777\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 90s 605ms/step - loss: 1.5058 - acc: 0.7213 - val_loss: 1.5187 - val_acc: 0.5800\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 97s 653ms/step - loss: 1.4881 - acc: 0.8345 - val_loss: 1.5071 - val_acc: 0.7905\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26f040095f8>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "modelbis.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['acc'])\n",
    "modelbis.fit(\n",
    "        train_batches,\n",
    "        steps_per_epoch=num_train // batch_size,\n",
    "        epochs=num_epoch,\n",
    "        validation_data=test_batches,\n",
    "        validation_steps=num_val // batch_size)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "65d89fe802b4c7e8a34936c074a27f823c11589e13db657f47b340f7d1549834"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}